{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import cv2 as cv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_IMAGE_W = 128\n",
    "INPUT_IMAGE_H = 128\n",
    "DIR = \"BrainHack/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(727, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'CT', 'MR', 'GE', 'Siemens', 'Philips', 'Toshiba', 'CTA', 'NCTT',\n",
       "       'T2W', 'T1W', 'DWI', 'FLAIR', 'GRE', ' 1_5', '3', 'AX', 'SAG', 'COR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(DIR + 'dataset.csv', delimiter = ',', header = 0)\n",
    "print(labels.shape)\n",
    "labels.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get file names and associate with their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_MR = glob.glob(os.path.join(DIR,'MRI','*','*','*','*','*.nii'))\n",
    "files_MR_name = []\n",
    "for files_MR_element in files_MR:\n",
    "    files_MR_name.append((files_MR_element.rsplit('/', 1)[-1])[:-4])\n",
    "len(files_MR_name)\n",
    "\n",
    "label_set = pd.DataFrame(columns = labels.columns)\n",
    "for name_idx, name in enumerate(files_MR_name):\n",
    "    temp = np.where(labels[\"Id\"] == name)[0][0]\n",
    "    label_set.loc[name_idx] = (labels.iloc[temp,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get the slices, associate with their labels and put them in an adequate format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = []\n",
    "raw_dataset_label = pd.DataFrame(columns = labels.columns)\n",
    "raw_dataset_label_idx = 0\n",
    "\n",
    "for file_idx, _ in enumerate(files_MR):\n",
    "    temp_file = nib.load(files_MR[file_idx], keep_file_open = False)\n",
    "    current_MRI_3D = temp_file.get_fdata()\n",
    "    temp_file.uncache()\n",
    "    #del temp_file\n",
    "    #print(\"\\rOpened the archive number {} of {}\". format(file_idx, len(files_MR)))\n",
    "    \n",
    "    if current_MRI_3D.ndim == 4:\n",
    "        for i in range(current_MRI_3D.shape[2]):\n",
    "            for j in range(current_MRI_3D.shape[3]):\n",
    "                raw_dataset.append(current_MRI_3D[:,:,i,j])\n",
    "                raw_dataset_label.loc[raw_dataset_label_idx] = label_set.loc[file_idx]\n",
    "                raw_dataset_label[\"Id\"][raw_dataset_label_idx] = raw_dataset_label[\"Id\"][raw_dataset_label_idx] + str(i) + \"_\" + str(j)\n",
    "                raw_dataset_label_idx = raw_dataset_label_idx + 1\n",
    "                \n",
    "    elif current_MRI_3D.ndim == 3:\n",
    "        for i in range(current_MRI_3D.shape[2]):\n",
    "                raw_dataset.append(current_MRI_3D[:,:,i])\n",
    "                raw_dataset_label.loc[raw_dataset_label_idx] = label_set.loc[file_idx]\n",
    "                raw_dataset_label[\"Id\"][raw_dataset_label_idx] = raw_dataset_label[\"Id\"][raw_dataset_label_idx] + str(i) + \"_0\"\n",
    "                raw_dataset_label_idx = raw_dataset_label_idx + 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reshaping and normalizing images to fixed values, Res: INPUT_IMAGE_W x INPUT_IMAGE_H and values: [0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_idx, _ in enumerate(raw_dataset):\n",
    "    raw_dataset[img_idx] = cv.resize(raw_dataset[img_idx], (INPUT_IMAGE_W, INPUT_IMAGE_H), interpolation = cv.INTER_AREA)      # cubic spline interpolation in a 4x4 environment\n",
    "\n",
    "#Normalizing slices accordingly to its minimum and maximum value\n",
    "#Question: would it be better to normalize it accordingly mapping the slices accordingly to the volume's min and max?\n",
    "for img_idx, _ in enumerate(raw_dataset):\n",
    "    raw_dataset[img_idx] =  cv.normalize(raw_dataset[img_idx], None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(raw_dataset) #-> OS DADOS ESTÃO ORGANIZADOS BONITINHOS AQUI!\n",
    "X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1) \n",
    "\n",
    "Y = raw_dataset_label.iloc[:,1:19]#->O GABARITO ESTÁ BONITINHO AQUI\n",
    "\n",
    "#WARNING: THERE IS A SPACE BEFORE 1_5!!! CORRECT THIS IN THE FUTURE\n",
    "Y_training = Y[[' 1_5', '3', 'AX', 'SAG', 'COR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying if the data is balanced\n",
      "Slices:\n",
      "Axial:  19936\n",
      "Sagital:  1925\n",
      "Coronal:  1015\n",
      "\n",
      "Static Magnetic Field:\n",
      "1.5T:  10390\n",
      "3T:  12486\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying if the data is balanced\")\n",
    "print(\"Slices:\")\n",
    "print(\"Axial: \", sum(Y_training['AX'] == 1))\n",
    "print(\"Sagital: \", sum(Y_training['SAG'] == 1))\n",
    "print(\"Coronal: \", sum(Y_training['COR'] == 1))\n",
    "\n",
    "print(\"\\nStatic Magnetic Field:\")\n",
    "print(\"1.5T: \", sum(Y_training[' 1_5'] == 1))\n",
    "print(\"3T: \", sum(Y_training['3'] == 1))\n",
    "\n",
    "y_slice = Y_training[['AX', 'SAG', 'COR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The slice projections are not balanced at all. The main static MF variations are. A strategy will be adopted before training the slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier for the MSMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training, X_test, y_training, y_test = train_test_split(X, Y_training, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_training, y_training, test_size=0.2222, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_FMS = y_train[[' 1_5', '3']]\n",
    "y_val_FMS = y_val[[' 1_5', '3']]\n",
    "y_test_FMS = y_test[[' 1_5', '3']]\n",
    "\n",
    "#y_train_slice = y_train[[ 'AX', 'SAG', 'COR']]\n",
    "#y_test_slice = y_test[[ 'AX', 'SAG', 'COR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FMS = Sequential()\n",
    "model_FMS.add(Conv2D(64, kernel_size=7, activation=\"relu\", input_shape=(INPUT_IMAGE_W,INPUT_IMAGE_H,1)))\n",
    "model_FMS.add(MaxPooling2D(pool_size=(7, 7), strides=None, padding='valid', data_format=None))\n",
    "#model_FMS.add(Conv2D(32, kernel_size=5, activation=\"relu\"))\n",
    "model_FMS.add(Flatten())\n",
    "model_FMS.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FMS.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FMS.fit(X_train, y_train_FMS, validation_data=(X_val, y_val_FMS), epochs=25, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FMS2 = Sequential()\n",
    "model_FMS2.add(Conv2D(128, kernel_size=7, activation=\"relu\", input_shape=(INPUT_IMAGE_W,INPUT_IMAGE_H,1)))\n",
    "model_FMS2.add(MaxPooling2D(pool_size=(7, 7), strides=None, padding='valid', data_format=None))\n",
    "#model_FMS2.add(Conv2D(32, kernel_size=5, activation=\"relu\"))\n",
    "model_FMS2.add(Flatten())\n",
    "model_FMS2.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FMS2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FMS2.fit(X_train, y_train_FMS, validation_data=(X_val, y_val_FMS), epochs=25, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FMS3 = Sequential()\n",
    "model_FMS3.add(Conv2D(32, kernel_size=5, activation=\"relu\", input_shape=(INPUT_IMAGE_W,INPUT_IMAGE_H,1)))\n",
    "model_FMS3.add(MaxPooling2D(pool_size=(7, 7), strides=None, padding='valid', data_format=None))\n",
    "model_FMS3.add(Conv2D(8, kernel_size=5, activation=\"relu\"))\n",
    "model_FMS3.add(Flatten())\n",
    "model_FMS3.add(Dense(2, activation=\"softmax\"))\n",
    "model_FMS3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "model_FMS3.fit(X_train, y_train_FMS, validation_data=(X_val, y_val_FMS), epochs=25, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_AX = Y_training.loc[Y_training.index[Y_training['AX'] == 1]]\n",
    "X_slice_AX = np.copy(X[Y_training.index[Y_training['AX'] == 1], :, :, :])\n",
    "\n",
    "Y_SAG = Y_training.loc[Y_training.index[Y_training['SAG'] == 1]]\n",
    "X_slice_SAG = np.copy(X[Y_training.index[Y_training['SAG'] == 1], :, :, :])\n",
    "\n",
    "Y_COR = Y_training.loc[Y_training.index[Y_training['COR'] == 1]]\n",
    "X_slice_COR = np.copy(X[Y_training.index[Y_training['COR'] == 1], :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicações para fatias axiais:  0 \n",
      "Replicações para fatias sagitais:  9 \n",
      "Replicações para fatias coronais:  18\n"
     ]
    }
   ],
   "source": [
    "Max_Sample = max(sum(Y_training['AX'] == 1), sum(Y_training['SAG'] == 1),sum(Y_training['COR'] == 1))\n",
    "\n",
    "conc_AX = Max_Sample//sum(Y_training['AX'] == 1)\n",
    "conc_SAG = Max_Sample//sum(Y_training['SAG'] == 1)\n",
    "conc_COR = Max_Sample//sum(Y_training['COR'] == 1)\n",
    "\n",
    "print(\"Replicações para fatias axiais: \", conc_AX-1, \"\\nReplicações para fatias sagitais: \", conc_SAG-1, \"\\nReplicações para fatias coronais: \", conc_COR-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 10000 is out of bounds for axis 0 with size 1925",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2e475fc2be78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_SAG_replicated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#plt.imshow(temp_SAG_replicated[id, :, :, 0], cmap = 'gray')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 10000 is out of bounds for axis 0 with size 1925"
     ]
    }
   ],
   "source": [
    "id = 10000\n",
    "plt.imshow(X_SAG_replicated[id, :, :, 0], cmap = 'gray')\n",
    "plt.show()\n",
    "#plt.imshow(temp_SAG_replicated[id, :, :, 0], cmap = 'gray')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_SAG_replicated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARTE SAGITAL:\n",
    "X_SAG_replicated = np.copy(X_slice_SAG)\n",
    "Y_SAG_replicated = Y_SAG\n",
    "\n",
    "temp_SAG_replicated = np.copy(X_SAG_replicated)\n",
    "for i, _ in enumerate(X_SAG_replicated):\n",
    "    temp = cv.flip(temp_SAG_replicated[i,:,:,:], 1)\n",
    "    temp_SAG_replicated[i, :, :, :] = temp.reshape(temp.shape[0], temp.shape[1], 1)\n",
    "\n",
    "\n",
    "X_SAG_replicated = np.concatenate([X_SAG_replicated, temp_SAG_replicated], axis = 0)\n",
    "Y_SAG_replicated = pd.concat([Y_SAG_replicated, Y_SAG_replicated], axis=0)\n",
    "########2x Bigger!#####\n",
    "\n",
    "gaussian_noise = np.random.normal(0, 0.05, (X_SAG_replicated.shape[0],X_SAG_replicated.shape[1], X_SAG_replicated.shape[2],X_SAG_replicated.shape[3]))\n",
    "X_SAG_replicated = np.concatenate([X_SAG_replicated, X_SAG_replicated + gaussian_noise], axis=0)\n",
    "Y_SAG_replicated = pd.concat([Y_SAG_replicated, Y_SAG_replicated], axis=0)\n",
    "# 4x Bigger\n",
    "gaussian_noise = np.random.normal(0, 0.05, (X_SAG_replicated.shape[0],X_SAG_replicated.shape[1], X_SAG_replicated.shape[2],X_SAG_replicated.shape[3]))\n",
    "X_SAG_replicated = np.concatenate([X_SAG_replicated, X_SAG_replicated + gaussian_noise], axis=0)\n",
    "Y_SAG_replicated = pd.concat([Y_SAG_replicated, Y_SAG_replicated], axis=0)\n",
    "# 8x Bigger (Duplicated with Flipped image + Version with Noise G(0, 1), and version G(0, 0.5))\n",
    "\n",
    "\n",
    "\n",
    "#PARTE CORONAL:\n",
    "X_COR_replicated = np.copy(X_slice_COR)\n",
    "Y_COR_replicated = Y_COR\n",
    "\n",
    "temp_COR_replicated = np.copy(X_COR_replicated)\n",
    "for i, _ in enumerate(X_COR_replicated):\n",
    "    temp = cv.flip(temp_COR_replicated[i,:,:,:], 1)\n",
    "    temp_COR_replicated[i, :, :, :] = temp.reshape(temp.shape[0], temp.shape[1], 1)\n",
    "\n",
    "\n",
    "X_COR_replicated = np.concatenate([X_COR_replicated, temp_COR_replicated], axis = 0)\n",
    "Y_COR_replicated = pd.concat([Y_COR_replicated, Y_COR_replicated], axis=0)\n",
    "########2x Bigger!#####\n",
    "\n",
    "gaussian_noise = np.random.normal(0, 0.05, (X_COR_replicated.shape[0],X_COR_replicated.shape[1], X_COR_replicated.shape[2],X_COR_replicated.shape[3]))\n",
    "X_COR_replicated = np.concatenate([X_COR_replicated, X_COR_replicated + gaussian_noise], axis=0)\n",
    "Y_COR_replicated = pd.concat([Y_COR_replicated, Y_COR_replicated], axis=0)\n",
    "# 4x Bigger\n",
    "gaussian_noise = np.random.normal(0, 0.05, (X_COR_replicated.shape[0],X_COR_replicated.shape[1], X_COR_replicated.shape[2],X_COR_replicated.shape[3]))\n",
    "X_COR_replicated = np.concatenate([X_COR_replicated, X_COR_replicated + gaussian_noise], axis=0)\n",
    "Y_COR_replicated = pd.concat([Y_COR_replicated, Y_COR_replicated], axis=0)\n",
    "# 8x Bigger (Duplicated with Flipped image + Version with Noise G(0, 1), and version G(0, 0.5))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for i in range(conc_SAG - 1):\n",
    "#    X_SAG_replicated = np.concatenate([X_SAG_replicated, X_slice_SAG], axis=0)\n",
    "#    Y_SAG_replicated = pd.concat([Y_SAG_replicated, Y_SAG], axis=0)\n",
    "#    \n",
    "#X_COR_replicated = X_slice_COR\n",
    "#Y_COR_replicated = Y_COR\n",
    "#for i in range(conc_COR - 1):\n",
    "#    X_COR_replicated = np.concatenate([X_COR_replicated, X_slice_COR], axis=0)\n",
    "#    Y_COR_replicated = pd.concat([Y_COR_replicated, Y_COR], axis=0)\n",
    "#    \n",
    "\n",
    "X_AX_replicated = X_slice_AX\n",
    "Y_AX_replicated = Y_AX\n",
    "#for i in range(conc_AX - 1):\n",
    "#    X_AX_replicated = np.concatenate([X_AX_replicated, X_slice_AX], axis=0)\n",
    "#    Y_AX_replicated = pd.concat([Y_AX_replicated, Y_AX], axis=0)\n",
    "#    \n",
    "X_slice = np.concatenate([X_AX_replicated, X_SAG_replicated, X_COR_replicated])\n",
    "for img_idx, _ in enumerate(X_slice):\n",
    "    temp = X_slice[img_idx]\n",
    "    temp =  cv.normalize(temp[:, :, 0], None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "    temp = temp.reshape(temp.shape[0], temp.shape[1], 1)\n",
    "    X_slice[img_idx] = temp\n",
    "    \n",
    "Y_slice = pd.concat([Y_AX_replicated, Y_SAG_replicated, Y_COR_replicated])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(cv.normalize(temp[:, :, 0], None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the data more balanced by decreasing the amount of each class to the one that has the least samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_slice = Y_slice[['AX', 'SAG', 'COR']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_slice = np.asarray(X_slice)\n",
    "X_slice = X_slice.reshape(X_slice.shape[0], X_slice.shape[1], X_slice.shape[2], 1)\n",
    "X_bal_training, X_bal_test, y_bal_training, y_bal_test = train_test_split(X_slice, Y_slice, test_size=0.1, random_state=42)\n",
    "X_bal_train, X_bal_val, y_bal_train, y_bal_val = train_test_split(X_bal_training, y_bal_training, test_size=0.222, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Slice = Sequential()\n",
    "model_Slice.add(Conv2D(8, kernel_size=3, activation=\"relu\", input_shape=(INPUT_IMAGE_W,INPUT_IMAGE_H,1)))\n",
    "model_Slice.add(Conv2D(4, kernel_size=3, activation=\"relu\"))\n",
    "model_Slice.add(Flatten())\n",
    "model_Slice.add(Dense(3, activation=\"softmax\"))\n",
    "model_Slice.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30427 samples, validate on 8683 samples\n",
      "Epoch 1/20\n",
      "30427/30427 [==============================] - 213s 7ms/step - loss: 0.0491 - accuracy: 0.9860 - val_loss: 0.0506 - val_accuracy: 0.9853\n",
      "Epoch 2/20\n",
      "30427/30427 [==============================] - 201s 7ms/step - loss: 0.0267 - accuracy: 0.9928 - val_loss: 0.0546 - val_accuracy: 0.9872\n",
      "Epoch 3/20\n",
      "30427/30427 [==============================] - 245s 8ms/step - loss: 0.0219 - accuracy: 0.9945 - val_loss: 0.0804 - val_accuracy: 0.9783\n",
      "Epoch 4/20\n",
      "30427/30427 [==============================] - 207s 7ms/step - loss: 0.0129 - accuracy: 0.9965 - val_loss: 0.0538 - val_accuracy: 0.9874\n",
      "Epoch 5/20\n",
      "30427/30427 [==============================] - 259s 9ms/step - loss: 0.0124 - accuracy: 0.9966 - val_loss: 0.0421 - val_accuracy: 0.9901\n",
      "Epoch 6/20\n",
      "30427/30427 [==============================] - 231s 8ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0590 - val_accuracy: 0.9902\n",
      "Epoch 7/20\n",
      "30427/30427 [==============================] - 227s 7ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0341 - val_accuracy: 0.9922\n",
      "Epoch 8/20\n",
      "30427/30427 [==============================] - 272s 9ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0464 - val_accuracy: 0.9906\n",
      "Epoch 9/20\n",
      "30427/30427 [==============================] - 240s 8ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0830 - val_accuracy: 0.9861\n",
      "Epoch 10/20\n",
      "30427/30427 [==============================] - 229s 8ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0464 - val_accuracy: 0.9910\n",
      "Epoch 11/20\n",
      "30427/30427 [==============================] - 261s 9ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0659 - val_accuracy: 0.9846\n",
      "Epoch 12/20\n",
      "30427/30427 [==============================] - 269s 9ms/step - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.0454 - val_accuracy: 0.9919\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1aa400ec18>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Slice.fit(X_bal_train, y_bal_train, validation_data=(X_bal_val, y_bal_val), epochs=20, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.29%\n"
     ]
    }
   ],
   "source": [
    "scores = model_Slice.evaluate(X_bal_test, y_bal_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 118\n",
    "print(y_train.iloc[idx,0:2])\n",
    "#plt.imshow(X_train[idx, :, :, 0], cmap = 'gray')\n",
    "plt.hist(X_train[idx, :, :, 0])\n",
    "plt.show()\n",
    "#plt.hist(img.ravel(),256,[0,256]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Slice.save(\"model_Slice.h5\")\n",
    "#model_FMS2.save(\"model_FMS.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_FMS = load_model(\"model_FMS.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.42%\n"
     ]
    }
   ],
   "source": [
    "scores = model_FMS.evaluate(X_test, y_test_FMS, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#incorrects = np.nonzero(model.predict_class(X_bal_test).reshape((-1,)) != y_bal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2288, 112]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-367735f01518>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_pred_FMS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_FMS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_FMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_FMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2288, 112]"
     ]
    }
   ],
   "source": [
    "y_pred_FMS = np.argmax(model_FMS.predict(X_test))\n",
    "confusion_matrix((y_test_FMS), to_categorical(y_pred_FMS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_FMS = (model_FMS.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/daniel_mac/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_FMS == np.amax(y_pred_FMS, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.0802304e-02, 9.5919770e-01],\n",
       "       [9.9805826e-01, 1.9417753e-03],\n",
       "       [9.9979109e-01, 2.0887452e-04],\n",
       "       ...,\n",
       "       [9.9985325e-01, 1.4676328e-04],\n",
       "       [4.3915221e-10, 1.0000000e+00],\n",
       "       [5.3327650e-01, 4.6672347e-01]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_FMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9591977 , 0.99805826, 0.9997911 , ..., 0.99985325, 1.        ,\n",
       "       0.5332765 ], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(y_pred_FMS, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
